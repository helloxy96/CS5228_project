{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import math\n",
    "import scikitplot as skplt\n",
    "import datetime\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score,auc,roc_curve,roc_auc_score, precision_recall_curve\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.impute import SimpleImputer\n",
    "from datetime import timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "default_rate_by_industry = {92: 0.33, 53: 0.33, 52: 0.34, 61: 0.38, 49: 0.38, 48: 0.39, 51: 0.4, \n",
    "                            56: 0.4, 23: 0.42, 44: 0.43, 45: 0.43, 72: 0.44, 71: 0.45, 81: 0.46, \n",
    "                            31: 0.47, 42: 0.47, 54: 0.48, 22: 0.52, 32: 0.53, 33: 0.57, 62: 0.65, \n",
    "                            21: 0.68, 11: 0.7, 0: 0.7, 55: 0.76}\n",
    "\n",
    "default_rate_by_state = {'FL': 0.36, 'TN': 0.41, 'GA': 0.41, 'SC': 0.42, 'AZ': 0.42, 'MI': 0.42, \n",
    "                         'NV': 0.43, 'IL': 0.43, 'KY': 0.45, 'MD': 0.45, 'NY': 0.46, 'DC': 0.46, \n",
    "                         'NJ': 0.47, 'UT': 0.48, 'CO': 0.48, 'TX': 0.48, 'CA': 0.49, 'VA': 0.49, \n",
    "                         'IN': 0.5, 'LA': 0.5, 'NC': 0.5, 'OH': 0.51, 'AR': 0.51, 'OK': 0.52, \n",
    "                         'DE': 0.52, 'HI': 0.53, 'MO': 0.54, 'MS': 0.54, 'AL': 0.55, 'OR': 0.55, \n",
    "                         'PA': 0.56, 'WA': 0.56, 'WV': 0.56, 'KS': 0.58, 'ID': 0.58, 'AK': 0.59, \n",
    "                         'MA': 0.59, 'CT': 0.59, 'WI': 0.6, 'MN': 0.61, 'NE': 0.62, 'RI': 0.63, \n",
    "                         'NM': 0.63, 'IA': 0.65, 'NH': 0.66, 'MT': 0.72, 'ME': 0.72, 'VT': 0.73, \n",
    "                         'SD': 0.75, 'WY': 0.76, 'ND': 0.77}\n",
    "\n",
    "def get_state_code(state):\n",
    "    #https://www.stateabbreviations.us/\n",
    "    state_map = {'AK': 1, 'AL': 2, 'AR': 3, 'AZ': 4,'CA': 5, 'CO': 6, 'CT': 7, 'DC': 8,\n",
    "                 'DE': 9, 'FL': 10, 'GA': 11, 'HI': 12, 'IA': 13, 'ID': 14, 'IL': 15, 'IN': 16, \n",
    "                 'KS': 17, 'KY': 18, 'LA': 19, 'MA': 20, 'MD': 21, 'ME': 22, 'MI': 23, 'MN': 24,\n",
    "                 'MO': 25, 'MS': 26, 'MT': 27, 'NC': 28, 'ND': 29, 'NE': 30, 'NH': 31, 'NJ': 32,\n",
    "                 'NM': 33, 'NV': 34, 'NY': 35, 'OH': 36, 'OK': 37, 'OR': 38, 'PA': 39, 'RI': 40,\n",
    "                 'SC': 41, 'SD': 42, 'TN': 43, 'TX': 44, 'UT': 45, 'VA': 46, 'VT': 47, 'WA': 48,\n",
    "                 'WI': 49, 'WV': 50, 'WY': 51}\n",
    "    if state in state_map:\n",
    "        return state_map[state]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def predict(model, df):\n",
    "    predict_submission = model.predict(df)\n",
    "    submission = pd.DataFrame(predict_submission)\n",
    "    submission.index.name = \"Id\"\n",
    "    submission.to_csv(\"predict.csv\", header=[\"ChargeOff\"])\n",
    "    \n",
    "\n",
    "def train_and_predict(model, df_train, df_predict):\n",
    "    # train\n",
    "    y = df_train[\"ChargeOff\"]\n",
    "    x = df_train.drop(['ChargeOff'], axis= 1)\n",
    "    model.fit(x, y)\n",
    "    \n",
    "    # test\n",
    "    predict = model.predict(df_predict)\n",
    "    submission = pd.DataFrame(predict)\n",
    "    submission.index.name = \"Id\"\n",
    "    submission.to_csv(\"predict.csv\", header=[\"ChargeOff\"])\n",
    "\n",
    "\n",
    "def train(model, df):\n",
    "    y = df[\"ChargeOff\"]\n",
    "    x = df.drop(['ChargeOff'], axis= 1)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\n",
    "    model.fit(x_train, y_train)\n",
    "    predict = model.predict(x_test)\n",
    "    print(classification_report(y_test, predict, digits=3))\n",
    "    print(\"AUC: {}\".format(roc_auc_score(y_test, predict)))\n",
    "\n",
    "    \n",
    "def pipeline(model, df):\n",
    "    y = df[\"ChargeOff\"]\n",
    "    x = df.drop(['ChargeOff'], axis= 1)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=2)\n",
    "    pipe = Pipeline(steps=[('feature_selection', SelectKBest(chi2, k=\"all\")), ('model', model)])\n",
    "    pipe.fit(x_train, y_train)\n",
    "    predict = pipe.predict(x_test)\n",
    "\n",
    "    print(classification_report(y_test, predict, digits=3))\n",
    "    \n",
    "    for name, importance in sorted(zip(x.columns, model.feature_importances_)):\n",
    "        print(name, \"=\", importance)\n",
    "\n",
    "\n",
    "def preprocessing(df):\n",
    "    df = df.drop(['Id', 'Name', 'City', 'Zip', 'BalanceGross'], axis= 1)\n",
    "    \n",
    "    # money columns\n",
    "    currency_cols = ['DisbursementGross', 'GrAppv', 'SBA_Appv']\n",
    "    df[currency_cols] = df[currency_cols].replace('[$,]', '', regex=True).astype(float)\n",
    "\n",
    "    # ApprovalFY column\n",
    "    df['ApprovalFY'] = df['ApprovalFY'].replace('1976A', 1976)\n",
    "    df['ApprovalFY'] = df['ApprovalFY'].astype(int)\n",
    "    \n",
    "    # NAICS\n",
    "    df['NAICS'] = df['NAICS'].replace(default_rate_by_industry)\n",
    "    df.rename(columns={\"NAICS\": \"Def_Rate_Industry\"}, inplace=True)\n",
    "    \n",
    "    # State, Bank and BankState\n",
    "    df['Bank_Same_State'] = np.where(df['State'] == df['BankState'], 1, 0)\n",
    "    df=pd.concat([df, pd.get_dummies(df['State'], prefix='State')], axis=1)\n",
    "    df= df.drop(['State'], axis =1 )\n",
    "    # df['State'] = df['State'].replace(default_rate_by_state)\n",
    "    # df['State'] = np.where(df['State'].isnull(), 0.54, df['State'])\n",
    "    # df.rename(columns={\"State\": \"Def_Rate_State\"}, inplace=True)\n",
    "    \n",
    "    banks = {v: k for k, v in enumerate(list(df['Bank'].unique()))}\n",
    "    df['Bank'].replace(banks, inplace=True)\n",
    "    bank_states = {v: k for k, v in enumerate(list(df['BankState'].unique()))}\n",
    "    df['BankState'].replace(bank_states, inplace=True)\n",
    "    \n",
    "    # FranchiseCode\n",
    "    df[\"FranchiseCode\"] = df[\"FranchiseCode\"].apply(lambda x: x != 0 and x != 1)\n",
    "    df.rename(columns={\"FranchiseCode\": \"Franchised\"}, inplace=True)\n",
    "    \n",
    "    # LowDoc column\n",
    "    df['LowDoc'] = np.where((df['LowDoc'] == \"N\") | (df['LowDoc'] == \"Y\"), df['LowDoc'], np.nan)\n",
    "    df['LowDoc'] = df['LowDoc'].replace({'N': 0, 'Y': 1})\n",
    "    df['LowDoc'] = np.where((df['LowDoc'].isnull()) & (df['DisbursementGross'] < 150000), 1, df['LowDoc'])\n",
    "    df['LowDoc'] = np.where((df['LowDoc'].isnull()) & (df['DisbursementGross'] >= 150000), 0, df['LowDoc'])\n",
    "    \n",
    "    # New Exist column\n",
    "    df['NewExist'] = np.where((df['NewExist'] == 2) | (df['NewExist'] == 1), df['NewExist'], np.nan)\n",
    "    df['NewExist'] = df['NewExist'].replace({2: 1, 1: 0})\n",
    "    \n",
    "    \n",
    "    # RevLineCr column\n",
    "    df['RevLineCr'] = np.where((df['RevLineCr'] == \"N\") | (df['RevLineCr'] == \"Y\"), df['RevLineCr'], np.nan)\n",
    "    df['RevLineCr'] = df['RevLineCr'].replace({'N': 0, 'Y': 1})\n",
    "    \n",
    "    df['RevLineCr'] = np.where(df['RevLineCr'].isnull(), df['RevLineCr'].mode(), df['RevLineCr'])\n",
    "    df['NewExist'] = np.where(df['NewExist'].isnull(), df['NewExist'].mode(), df['NewExist'])\n",
    "    \n",
    "\n",
    "\n",
    "    # date columns\n",
    "    df[['ApprovalDate', 'DisbursementDate']] = df[['ApprovalDate', 'DisbursementDate']].apply(pd.to_datetime)\n",
    "    df['DisbursementDate'] = np.where(df['DisbursementDate'].isnull(), df['ApprovalDate'] + timedelta(days=94), df['DisbursementDate'])\n",
    "\n",
    "    # two recession calculation\n",
    "    df['DisbursementFY'] = df['DisbursementDate'].map(lambda x: x.year)\n",
    "    df['GreatRecession'] = np.where(((2007 <= df['DisbursementFY']) & (df['DisbursementFY'] <= 2009)) | \n",
    "                                    ((df['DisbursementFY'] < 2007) & \n",
    "                                     (df['DisbursementFY'] + (df['Term']/12) >= 2007)), 1, 0)\n",
    "    \n",
    "    # SVA vs Gross\n",
    "    df['SBA_vs_Gross'] = df['SBA_Appv']/df['GrAppv']\n",
    "    \n",
    "    # AppvDisbursed\n",
    "    df['Appv_Disbur_Same'] = np.where(df['DisbursementGross'] == df['GrAppv'], 1, 0)\n",
    "\n",
    "    # RealEstate\n",
    "    df['RealEstate'] = np.where(df['Term'] >= 240, 1, 0)\n",
    "    \n",
    "    df[\"CreateJob\"] = df[\"CreateJob\"].apply(lambda x: x != 0)\n",
    "    df[\"RetainedJob\"] = df[\"RetainedJob\"].apply(lambda x: x != 0)\n",
    "        \n",
    "    df = df.drop(['ApprovalDate', 'DisbursementDate', 'DisbursementFY'], axis= 1)\n",
    "    \n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('Xtrain.csv', dtype={\"ApprovalFY\": object})\n",
    "df_y = pd.read_csv('Ytrain.csv')\n",
    "df_train = pd.concat([df_train, df_y['ChargeOff']], axis=1, sort=False)\n",
    "df_train = preprocessing(df_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.915     0.903     0.909      5101\n",
      "           1      0.900     0.913     0.906      4899\n",
      "\n",
      "    accuracy                          0.908     10000\n",
      "   macro avg      0.908     0.908     0.908     10000\n",
      "weighted avg      0.908     0.908     0.908     10000\n",
      "\n",
      "AUC: 0.9076996977846841\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "df_new = df_train\n",
    "# df_new = df_train[[\"RevLineCr\", \"Term\",\"SBA_vs_Gross\", \"GrAppv\", \"Def_Rate_State\", \"DisbursementGross\", \"RetainedJob\"\n",
    "#                 ,\"Def_Rate_Industry\", \"GreatRecession\", \"CreateJob\", \"ChargeOff\"]]\n",
    "model = XGBClassifier()\n",
    "train(model, df_new)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "\n",
    "def optimal_model(clf, params,x_train,y_train, x_test, y_test):\n",
    "    \n",
    "    search = GridSearchCV(estimator=clf,\n",
    "                          param_grid=params,\n",
    "                          scoring = 'f1',\n",
    "                          n_jobs = -1,\n",
    "                          cv = 3,\n",
    "                          verbose=True)\n",
    "\n",
    "    \n",
    "    search.fit(x_train, y_train)\n",
    "    \n",
    "    best = search.best_estimator_\n",
    "    best_model = best.fit(x_train, y_train)\n",
    "    print('Best parameters: \\n',search.best_params_)\n",
    "    print('='*70)\n",
    "    \n",
    "    y_test_ypred = best_model.predict(x_test)\n",
    "    print('Classification Report: \\n', classification_report(y_test, y_test_ypred, digits=3))\n",
    "    print('='*100)\n",
    "    return best_model\n",
    "\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 576 candidates, totalling 1728 fits\n",
      "Best parameters: \n",
      " {'colsample_bytree': 0.5, 'gamma': 0.1, 'max_depth': 7, 'min_child_weight': 5, 'n_estimators': 250}\n",
      "======================================================================\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.971     0.956     0.964      2574\n",
      "           1      0.955     0.969     0.962      2426\n",
      "\n",
      "    accuracy                          0.963      5000\n",
      "   macro avg      0.963     0.963     0.963      5000\n",
      "weighted avg      0.963     0.963     0.963      5000\n",
      "\n",
      "====================================================================================================\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   56.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 22.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 37.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1728 out of 1728 | elapsed: 57.8min finished\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#For finding best parameters\n",
    "# params ={\"max_depth\"        : [ 6, 7, 8, 9],\n",
    "#          \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    "#          \"gamma\"            : [ 0.0, 0.1, 0.2 ],\n",
    "#          \"colsample_bytree\" : [ 0.3, 0.4, 0.5],\n",
    "#          \"n_estimators\"     : [ 150, 200, 250, 300]}\n",
    "# \n",
    "# \n",
    "# \n",
    "# xgb = XGBClassifier(base_score = 0.5, booster = 'gbtree', \n",
    "#                     colsample_bylevel = 1, colsample_bynode = 1, \n",
    "#                     colsample_bytree = 0.5, gamma = 0.0,\n",
    "#                     learning_rate = 0.15, max_delta_step = 0, \n",
    "#                     max_depth = 6, min_child_weight = 1, \n",
    "#                     missing = None, n_estimators = 150, \n",
    "#                     n_jobs = 1, objective ='binary:logistic',\n",
    "#                     reg_alpha = 0, reg_lambda = 1, scale_pos_weight = 1, \n",
    "#                     subsample = 1, verbosity = 1)\n",
    "# \n",
    "# y = df_new[\"ChargeOff\"]\n",
    "# x = df_new.drop(['ChargeOff'], axis= 1)\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=2)\n",
    "# best_model = optimal_model(xgb, params, x_train, y_train, x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.944     0.934     0.939      5101\n",
      "           1      0.932     0.942     0.937      4899\n",
      "\n",
      "    accuracy                          0.938     10000\n",
      "   macro avg      0.938     0.938     0.938     10000\n",
      "weighted avg      0.938     0.938     0.938     10000\n",
      "\n",
      "AUC: 0.9379857957240872\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#Best parameters: \n",
    " #{'colsample_bytree': 0.5, 'gamma': 0.1, 'max_depth': 7, 'min_child_weight': 5, 'n_estimators': 250}\n",
    "xgb = XGBClassifier(base_score = 0.5, booster = 'gbtree', \n",
    "                    colsample_bylevel = 1, colsample_bynode = 1, \n",
    "                    colsample_bytree = 0.5, gamma = 0.1,\n",
    "                    learning_rate = 0.15, max_delta_step = 0, \n",
    "                    max_depth = 7, min_child_weight = 5, \n",
    "                    missing = None, n_estimators = 250, \n",
    "                    n_jobs = 1, objective ='binary:logistic',\n",
    "                    reg_alpha = 0, reg_lambda = 1, scale_pos_weight = 1, \n",
    "                    subsample = 1, verbosity = 1)\n",
    "\n",
    "train(xgb, df_new)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# df_test = pd.read_csv('Xtest.csv', dtype={\"ApprovalFY\": object})\n",
    "# df_test = preprocessing(df_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# predict = best_model.predict(df_test)\n",
    "# submission = pd.DataFrame(predict)\n",
    "# submission.index.name = \"Id\"\n",
    "# submission.to_csv(\"predict.csv\", header=[\"ChargeOff\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}